# sql-database-to-insights
Building a relational database from scratch, cleaning and transforming the data, and running SQL/Python-based analytics.

In this project, we worked with the dataset extracted from Reddit in May 2015, which contains over 4 millions rows. Our first objective is to construct and manage a large-scale dataset in an optimized database structure; and second, to develop hands-on experience in exploring big data using SQL queries.
To achieve these objectives, we began by designing a comprehensive database schema that could accurately model the complex relationships within the data.

<img width="1010" height="590" alt="schema (1)" src="https://github.com/user-attachments/assets/01b16855-e73f-43a5-b252-2d9d362d6b5e" />

We then created tables based on this schema, imported the dataset into these tables, and conducted initial explorations to gain insights into the structure and content of the data. Additionally, we selected a smaller representative sample from the full database.

Following our database work, we moved on to the natural language processing (NLP) component of the project. In this phase, we applied various NLP techniques to analyze the comments. This approach allows us to uncover key aspects of the dataset, including the detection of flagged comments, the underlying scoring mechanism of comments, and the identification of popular topics within the Reddit community.
